{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "#from emfdscore.scoring import score_docs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('transcripts/emfd_out.csv')\n",
    "df = df[df['count']>=60]\n",
    "y = df.pop('Y')\n",
    "df.insert(0, 'Y', y)\n",
    "data = df.drop(df.loc[:, 'care_sent':'count'].columns, axis = 1)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(['index'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = np.split(data.sample(frac=1, random_state=42), [int(.7*len(data)), int(.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab_char = {}\n",
    "Vocab_char[0] = '<unk>'\n",
    "i=1\n",
    "for char in train['Y'].unique():\n",
    "    Vocab_char[i] = char\n",
    "    i+=1\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in Vocab_char.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "\n",
    "def preprocess_data(df):\n",
    "    rv = []\n",
    "    records = df.loc[:, 'care_p':'sanctity_p'].to_records(index=False)\n",
    "    results = list(records)\n",
    "    for i in range(len(df)):\n",
    "        rv.append((df['Y'].iloc[i], results[i]))\n",
    "    return rv\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    speech_mf = []\n",
    "    labels = []\n",
    "    \n",
    "    for b in batch:\n",
    "        label = get_key(b[0])\n",
    "        labels.append(label)\n",
    "        s = [i for i in b[1]]\n",
    "        speech_mf.append(s)\n",
    "    print(labels)\n",
    "    speech_mf = torch.tensor(speech_mf)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return labels, speech_mf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(Vocab_char)\n",
    "vocab_size = 5\n",
    "\n",
    "class NNeMFDTagger(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "\n",
    "        super(NNeMFDTagger, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "def train_an_epoch(dataloader):\n",
    "    model.train()\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, speech_mf) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "        print(speech_mf)\n",
    "        probs = model(speech_mf)\n",
    "        loss = loss_function(probs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():    \n",
    "        total_acc, total_count = 0, 0\n",
    "        for idx, (label, speech_mf) in enumerate(dataloader):\n",
    "            log_probs = model(speech_mf)\n",
    "            total_acc += (log_probs.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "  \n",
    "train_data = preprocess_data(train)\n",
    "valid_data = preprocess_data(valid)\n",
    "test_data = preprocess_data(test)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, \n",
    "                             collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNeMFDTagger(len(Vocab_char),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 1, 1, 21, 51, 10, 2, 1, 1, 10, 1, 35, 14, 21, 17, 1, 1, 9, 1, 1, 51, 10, 10, 10, 1, 1, 1, 27, 16, 22, 48, 1, 32, 1, 42, 29, 25, 5, 10, 10, 20, 39, 25, 5, 37, 1, 29, 1, 52, 10, 10, 2, 3, 12, 14, 14, 10, 42, 3, 29, 31, 25, 30, 25]\n",
      "tensor([[0.1143, 0.1032, 0.0933, 0.0985, 0.0877],\n",
      "        [0.0940, 0.0993, 0.0910, 0.0838, 0.0776],\n",
      "        [0.1155, 0.0968, 0.1213, 0.0940, 0.0723],\n",
      "        [0.1185, 0.0998, 0.1306, 0.1183, 0.0948],\n",
      "        [0.0983, 0.1095, 0.0925, 0.1025, 0.0838],\n",
      "        [0.1179, 0.1152, 0.0922, 0.0912, 0.0695],\n",
      "        [0.1379, 0.1140, 0.1068, 0.0900, 0.1020],\n",
      "        [0.0917, 0.0928, 0.0964, 0.0906, 0.0741],\n",
      "        [0.0376, 0.0707, 0.1099, 0.1149, 0.0415],\n",
      "        [0.1119, 0.0906, 0.1017, 0.0860, 0.0799],\n",
      "        [0.0598, 0.0845, 0.0931, 0.0910, 0.0667],\n",
      "        [0.1187, 0.1118, 0.0946, 0.0915, 0.0860],\n",
      "        [0.0977, 0.0893, 0.0941, 0.1152, 0.0716],\n",
      "        [0.0802, 0.0996, 0.0911, 0.0894, 0.0746],\n",
      "        [0.1113, 0.1056, 0.1044, 0.0901, 0.0853],\n",
      "        [0.1091, 0.1063, 0.1009, 0.0906, 0.0768],\n",
      "        [0.1053, 0.1325, 0.1080, 0.1079, 0.0904],\n",
      "        [0.0729, 0.0908, 0.0746, 0.0692, 0.0607],\n",
      "        [0.0890, 0.0986, 0.0987, 0.1035, 0.0764],\n",
      "        [0.1031, 0.1083, 0.0925, 0.1123, 0.0894],\n",
      "        [0.1152, 0.1023, 0.1103, 0.0917, 0.0838],\n",
      "        [0.0866, 0.0862, 0.0979, 0.0847, 0.0679],\n",
      "        [0.0742, 0.0686, 0.0702, 0.0686, 0.0844],\n",
      "        [0.0965, 0.0828, 0.0881, 0.0801, 0.0812],\n",
      "        [0.1041, 0.1036, 0.0883, 0.0892, 0.0760],\n",
      "        [0.1185, 0.1112, 0.0961, 0.1080, 0.0830],\n",
      "        [0.1064, 0.1152, 0.1011, 0.1003, 0.0893],\n",
      "        [0.0893, 0.0899, 0.0947, 0.1017, 0.0687],\n",
      "        [0.1213, 0.0996, 0.1050, 0.0941, 0.0869],\n",
      "        [0.1135, 0.1135, 0.0952, 0.1105, 0.0872],\n",
      "        [0.0923, 0.0896, 0.0978, 0.0969, 0.0822],\n",
      "        [0.0905, 0.0976, 0.0718, 0.0840, 0.0982],\n",
      "        [0.0991, 0.1003, 0.0954, 0.0850, 0.0882],\n",
      "        [0.0763, 0.0609, 0.1071, 0.0722, 0.0686],\n",
      "        [0.1054, 0.0968, 0.0961, 0.1020, 0.0735],\n",
      "        [0.1064, 0.1245, 0.0851, 0.1247, 0.0618],\n",
      "        [0.1079, 0.1158, 0.0779, 0.0979, 0.0932],\n",
      "        [0.0968, 0.1009, 0.0848, 0.0864, 0.0780],\n",
      "        [0.1209, 0.0951, 0.0977, 0.1034, 0.0845],\n",
      "        [0.1095, 0.0972, 0.0820, 0.0770, 0.0793],\n",
      "        [0.0986, 0.0989, 0.0922, 0.0878, 0.0749],\n",
      "        [0.0839, 0.0865, 0.0821, 0.0725, 0.0664],\n",
      "        [0.0917, 0.1042, 0.0929, 0.0765, 0.0832],\n",
      "        [0.0743, 0.0668, 0.0629, 0.0604, 0.0518],\n",
      "        [0.1354, 0.1139, 0.0950, 0.1007, 0.0992],\n",
      "        [0.0898, 0.0922, 0.1081, 0.1082, 0.0889],\n",
      "        [0.0968, 0.1358, 0.0849, 0.1006, 0.1105],\n",
      "        [0.1032, 0.0905, 0.0841, 0.0956, 0.0691],\n",
      "        [0.1427, 0.1713, 0.1365, 0.1459, 0.1254],\n",
      "        [0.1028, 0.0820, 0.0763, 0.0716, 0.0800],\n",
      "        [0.0899, 0.0905, 0.0899, 0.0885, 0.0825],\n",
      "        [0.1114, 0.1050, 0.0842, 0.0854, 0.0746],\n",
      "        [0.1024, 0.1131, 0.0935, 0.1035, 0.0886],\n",
      "        [0.1050, 0.0986, 0.0922, 0.0880, 0.0829],\n",
      "        [0.0998, 0.0833, 0.0812, 0.0724, 0.0711],\n",
      "        [0.1107, 0.1245, 0.0899, 0.0899, 0.0807],\n",
      "        [0.0626, 0.0633, 0.0689, 0.0702, 0.0593],\n",
      "        [0.0985, 0.0962, 0.0902, 0.0949, 0.0801],\n",
      "        [0.1110, 0.1067, 0.0910, 0.0974, 0.0791],\n",
      "        [0.1420, 0.0656, 0.0822, 0.0869, 0.0622],\n",
      "        [0.0884, 0.0989, 0.0744, 0.0846, 0.0734],\n",
      "        [0.1358, 0.1143, 0.1308, 0.1101, 0.0818],\n",
      "        [0.0963, 0.1026, 0.0902, 0.0885, 0.0732],\n",
      "        [0.1224, 0.1161, 0.0949, 0.0883, 0.0914]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-ec54abae4e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_an_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-95f70070e280>\u001b[0m in \u001b[0;36mtrain_an_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-4f42194577f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bow_vec)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "EPOCHS = 3 # epoch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print(f'Epoch: {epoch}, time taken: {time_taken:.1f}s, validation accuracy: {accuracy:.3f}.')\n",
    "    \n",
    "plt.plot(range(1, EPOCHS+1), accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
