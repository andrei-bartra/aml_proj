{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "#from emfdscore.scoring import score_docs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('transcripts/emfd_out.csv')\n",
    "df = df[df['count']>=60]\n",
    "y = df.pop('Y')\n",
    "df.insert(0, 'Y', y)\n",
    "data = df.drop(df.loc[:, 'care_sent':'count'].columns, axis = 1)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(['index'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = np.split(data.sample(frac=1, random_state=42), [int(.7*len(data)), int(.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab_char = {}\n",
    "Vocab_char[0] = '<unk>'\n",
    "i=1\n",
    "for char in train['Y'].unique():\n",
    "    Vocab_char[i] = char\n",
    "    i+=1\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in Vocab_char.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "\n",
    "def preprocess_data(df):\n",
    "    rv = []\n",
    "    records = df.loc[:, 'care_p':'sanctity_p'].to_records(index=False)\n",
    "    results = list(records)\n",
    "    for i in range(len(df)):\n",
    "        rv.append((df['Y'].iloc[i], results[i]))\n",
    "    return rv\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    speech_mf = []\n",
    "    labels = []\n",
    "    \n",
    "    for b in batch:\n",
    "        label = get_key(b[0])\n",
    "        labels.append(label)\n",
    "        s = [i for i in b[1]]\n",
    "        speech_mf.append(s)\n",
    "    speech_mf = torch.tensor(speech_mf)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return labels, speech_mf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24fcfff8c553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "t1,t2 = collate_fn(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1113, 0.0873, 0.1189, 0.1097, 0.0749],\n",
       "        [0.0985, 0.1028, 0.0845, 0.1074, 0.0820],\n",
       "        [0.1110, 0.1058, 0.0891, 0.0836, 0.0791],\n",
       "        ...,\n",
       "        [0.1099, 0.1036, 0.1009, 0.0907, 0.0842],\n",
       "        [0.0956, 0.1176, 0.0994, 0.0744, 0.0834],\n",
       "        [0.0928, 0.0864, 0.1055, 0.0921, 0.0727]], dtype=torch.float64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(Vocab_char)\n",
    "vocab_size = 5\n",
    "\n",
    "class NNeMFDTagger(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "\n",
    "        super(NNeMFDTagger, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "def train_an_epoch(dataloader):\n",
    "    model.train()\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, speech_mf) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "        probs = model(speech_mf.float())\n",
    "        loss = loss_function(probs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():    \n",
    "        total_acc, total_count = 0, 0\n",
    "        for idx, (label, speech_mf) in enumerate(dataloader):\n",
    "            log_probs = model(speech_mf.float())\n",
    "            total_acc += (log_probs.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "  \n",
    "train_data = preprocess_data(train)\n",
    "valid_data = preprocess_data(valid)\n",
    "test_data = preprocess_data(test)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, \n",
    "                             collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNeMFDTagger(len(Vocab_char),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, time taken: 0.3s, validation accuracy: 0.008.\n",
      "Epoch: 2, time taken: 0.3s, validation accuracy: 0.029.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "EPOCHS = 3 # epoch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print(f'Epoch: {epoch}, time taken: {time_taken:.1f}s, validation accuracy: {accuracy:.3f}.')\n",
    "    \n",
    "plt.plot(range(1, EPOCHS+1), accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
